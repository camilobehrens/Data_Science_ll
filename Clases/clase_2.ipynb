{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL y Adquisición de datos\n",
    "## 1. Adquisición de datos\n",
    "Se refiere al proceso de **recolección**, **filtrado** y **limpieza** de datos antes de colocarlos en un almacén de datos o cualquier otra solución de almacenamiento.\n",
    "\n",
    "## 2. Comprensión del problema de negocio y Definición de la Necesidad de Datos\n",
    "Antes de comenzar con la adquisición de datos, es esencial comprender el problema de negocio o investigación que se desea resolver.\n",
    "\n",
    "Definir la pregunta problema es el primer paso: ¿qué se quiere analizar o predecir? ¿qué tipo de datos son necesarios para ello? ¿dónde se pueden encontrar esos datos? Es fundamental identificar la relevancia de los datos con respecto al objetivo planteado.\n",
    "\n",
    "## 3.1 Datos Estructurados\n",
    "Los datos estructurados tienen un formato bien definido, generalmente organizado en **tablas** con **filas** y **columnas**.\n",
    "Ejemplos comunes incluyen bases de datos relacionales y archivos CSV. Sumaturaleza bien organizada facilita el almacenamiento, búsqueda y análisis a través de consulta SQL y otras herramientas similares.\n",
    "\n",
    "## 3.2 Datos Semi-estructurados\n",
    "Estos datos no siguen un esquema rígido, pero sí presentan cierta organización,como archivos JSON o XML. Este tipo de datos es más flexible que los estructurados y pueden adaptarse a diferentes necesidades de almacenamiento y análisis, aunque su procesamiento puede requerir técnicas más avanzadas.\n",
    "\n",
    "## 3.3 Datos No Estructurados\n",
    "Los datos no estructurados carecen de un formato predefinido y son más difíciles de procesar. Ejemplos de estos datos incluyen textos, imágenes y videos. Debido a su complejidad y diversidad, el análisis de datos no estructurados suele requerir técnicas de procesamientos avanzado, como el procesamiento de lenguaje natural (NLP) o la visión por computadora.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Herramientas y técnicas para la lectura de datos con Pandas\n",
    "\n",
    "Pandas es una biblioteca de Python ampliamente utilizada para la manipulación y análisi de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alguas de las técnicas más comunes para leer datos desde diferentes fuentes:\n",
    "\n",
    "## 1. Lectura de datos desde un archivo de texto plano (CSV, TSV, etc.)\n",
    "import pandas as pd\n",
    "pd.read_csv('ruta_o_url_del_archivo.csv')\n",
    "\n",
    "## 2. Lectura de datos desde un archivo de Excel\n",
    "pd.read_excel('ruta_o_url_del_archivo.xlsx', \n",
    "sheet_name = 'nombre_de_la_hoja')\n",
    "\n",
    "## 3. Lectura de datos desde una base de datos SQL\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('ruta_o_url_de_la_base_de_datos.db')\n",
    "df = pd.read_sql_query('SELECT * FROM nombre_de_la_tabla', conn)\n",
    "\n",
    "## 4. Lectura de datos desde una API\n",
    "import requests\n",
    "response = requests.get('url_de_la_api')\n",
    "data = response.json()\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas técnicas permites a los cientificos de datos acceder a múltiples fuentes de información y estructurar los datos para su análisis. La capacidad de leer y manipular datos de diferentes formatos es crucial para trabajar de manera efectiva en proyectos de ciencia de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repositorios y fuentes de datos\n",
    "\n",
    "Existen múltiples fuentes de datos disponibles, tanto gratuitas como de pago, que pueden ser utilizadas para distintos propósitos analíticos y de medelado. A continuación, se presentan algunos ejemplos de repositorios gratuitos y una descripción detallada del proceso de adquisición de datos desde APIs públicas y privadas.\n",
    "\n",
    "### Ejemplos de repositorios gratuitos de datos.\n",
    "\n",
    "1. **Kaggle Kaggle** es una de las plataformas más populares para los cientificos de datos, que ofrece miles de conjuntos de datos gratuitos en diversas áreas como finanzas, salud, tecnología, entre otros. Los usuarios pueden descargar los datos directamente o conectarse a Kaggle mediante su API.\n",
    "\n",
    "2. **Google Dataset Search** es un motor de búsqueda que ayuda a encontrar conjuntos de datos enla web. Google Dataset Search incluye datos de numerosas fuentes, desde datos académicos hasta repositorios gubernamentales.\n",
    "\n",
    "3. **UCI Machine Learning Repository** es un repositorio que ofrece una gran variedad de conjuntos de datos, especialmente útiles para proyectos académicos y de investigación. Es ampliamentes utilizado para proyectos de aprendizaje automático y análisis de datos.\n",
    "\n",
    "4. **Data.gov** es el repositorio abierto de datos del gobierno de los estados unidos, que contiene conjuntos de datos de diferentes agencias gubernamentales. Es una excelente fuente de datos relacionados con temas como salud, energía, educación y clima.\n",
    "\n",
    "5. **World Bank Open Data** del Banco Mundial proporciona acceso gratuito a sus datos sobre desarrollo mundial. Los datos abarcan temas como economía, salud, educación y más, permitiendo el acceso a información detallada a nivel global. \n",
    "\n",
    "6. **AWS Public Datasets** de Amazon Web Services ofrece una colección de conjuntos de datos de uso público, alojados en la nube para facilitar su acceso y procesamiento. Incluye datos sobre genómica, imágenes satelitales y mucho más.\n",
    "\n",
    "\n",
    "### Descripción del proceso de adquisición de datos desde APIs públicas y privadas.\n",
    "Las APIs (Interfaces de Programación de Aplicaciones) son herramientas poderosas para la adquisición de datos, permitioendo a los desarrolladores y cientificos de datos acceder a datos en tiempo real desde diversas fuentes. Las APIs pueden públicas, accesibles sin autentificación, o privadas, que requieren una clave de API o credenciales específicas.\n",
    "\n",
    "### Pasos para adquirir datos desde APIs públicas\n",
    "\n",
    "1. **Identificar la API de ínteres:** el primer paso es identificar una API que proporcione los datos que se necesitan. Ejemplo de APIs públicas incluyen la API de OpenWeather para datos meteorológicos y la API de CoinGecko para datos de criptomonedas. \n",
    "\n",
    "2. **Consultar la Documentación de la API:** La documentación es esencial para entender cómo funciona la API, los endpoints disponibles, los parámetros que puedes pasar y el formatos en el que se devuelven los datos (generalmente JSON o XML)\n",
    "\n",
    "3. **Enviar una Solicitud (Request)** a la API: se utilizan bibliotecas como ```requests```en Python para enviar una solicitud a la API. Por ejemplo, para consultar la API de OpenWeather, puedes hacer los siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# URL de la API y parametros\n",
    "url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "params = {\n",
    "    \"q\": \"London,uk\", #ciudad de interés\n",
    "    \"appid\":, #'tu clave de API'\n",
    "    \"units\": \"metric\" #unidades de temperatura\n",
    "}\n",
    "\n",
    "# envío de la solicitud\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Manejo de Errores y validación de respuestas:** verificar siempre el código de estado de la respuesta (e.g., 200 para éxito, 404 para no encontrado). Maneja posibles errores para asegurar que el script se ejecute sin interrupciones.\n",
    "\n",
    "5. **Procesamiento de los Datos:** los datos obtenidos se sueles transformar en un DataFrame de Pandas para su manipulación y análisis. Esto facilitas la limpieza, transformación y visualización de los datos adquiridos.\n",
    "\n",
    "### Adquisición de datos desde APIs privadas\n",
    "\n",
    "1. **Registrarse y obtener una clave API:** para acceder a APIs privadas, primero debes registrarte en la plataforma que ofrece la API y obtener una clave de acceso, conocida como API Key. Esta clave debe incluirse en cada solicitud para autenticar tu acceso.\n",
    "\n",
    "2. **Configurar la Solicitud de API con credenciales:** incluye tu API Key en los encabezados o parámetros de la solicitud. Aquí hay un ejemplo básico para una API privada:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# URL de la API y parametros\n",
    "url = \"https://api.ejemplo.com/data\"\n",
    "headers = { 'Authorization': 'Bearer tu_clave_api' # Encabezado de autenticación }\n",
    "           \n",
    "# envío de la solicitud\n",
    "response = requests.get(url, headers=headers)\n",
    "data = response.json()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Seguridad y Mantenimiento de Credenciales:** mantén tus claves de API segura. No las compartas ni subas a repositorios públicos. Utiliza archivos de configuración o variables de entorno para manejar las claves de manera segura.\n",
    "\n",
    "4. **Limitaciones y Manejo de Límites de Uso:** las APIs privadas a menudo tienen limitaciones de uso (rate limits) que restringen la cantidad de solicitudes que se pueden hacer en un período determinado. Asegúrate de gestionar estos límites y respetar los términos de uso para evitar bloqueos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indices",
   "language": "python",
   "name": "indices"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
