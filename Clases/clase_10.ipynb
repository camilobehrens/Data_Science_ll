{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9933348d",
   "metadata": {},
   "source": [
    "# 10. ML y Mejoras de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e73bd4",
   "metadata": {},
   "source": [
    "## 10.1 Introducción a CRISP-DM\n",
    "\n",
    "*CRISP-DM* (Cross-Industry Standard for Data Mining) es una metodología estándar y probada que se utiliza para guiar proyectos de meneria de datos. Este modelo ofrece una estructura clara y comprensible que permite a los equipos abordar problemas de análisis de datos en distintos contextos industriales.\n",
    "\n",
    "Como metodología, CRISP-DM incluye descripciones detalladas de las fases típicas de un proyecto de mineria de datos, las tareas necesarias en cada fase y la explicación de cómo se relacionan estas tareas entre sí. Su diseño modular permite adaptarse a proyectos de diferentes escalas y complejidades.\n",
    "\n",
    "En su forma más general CRISP-DM abarco todo el ciclo de vida de la minería de datos, ofreciendo una guía práctica desde la comprensión del negocio y los datos hasta la implementación de modelos y el despliegue de soluciones. Esto ayuda a que los equipos mantengan un enfoque consistente y estructurado, asegurando que los proyectos de minería de datos estén alineados con los objetivos comerciales y científicos.\n",
    "\n",
    "\n",
    "\n",
    "### Fases de CRISP-DM\n",
    "\n",
    "CRISP-DM se divide en seis fases interconectadas que representan un ciclo iterativo de trabajo. A continuación se describen las seis fases principales:\n",
    "\n",
    "\n",
    "1. **Comprensión del negocio**\n",
    "\n",
    "El objetivo de esta fase es entender los objetivos y requisitos del proyecto desde una perspectiva comercial. Se recomienda involucrar a equipos interdisciplinarios para definir claramente las expectativas del análisis de datos. Este paso asegura que los recursos y esfuerzos estén alineados con los objetivos estratégicos de la organización.\n",
    "\n",
    "Entre las tareas clave están: recopilar información sobre la situación actual del negocio y establecer los objetivos a corto, mediano y largo plazo.\n",
    "\n",
    "\n",
    "\n",
    "2. **Comprensión de los datos**\n",
    "\n",
    "En esta fase, el equipo se enfoca en conocer y explorar los datos disponibles. Esto implica obtener acceso a los datos y evaluarlos mediante análisis descriptivos y visuales. Se busca identificar problemas potenciales en los datos, como valores faltantes o inconsistencias. Las actividades incluyen la recopilación de datos, su descripción detallada, la exploración mediante gráficos y la verificación de su calidad.\n",
    "\n",
    "\n",
    "3. **Preparación de los datos**\n",
    "\n",
    "La preparación de los datos suele ser la fase más extensa, ocupando entre el 50% y 70% del tiempo total del proyecto. En esta etapa, se transforman los datos brutos en un formato adecuado para el modelado. Entre las tareas más comunes se encuentra la fusión de conjuntos de datos, la selección de muestras, la agregación de registros, la creación de nuevas variables y la eliminación o imputación de valores faltantes. Además, se preparan los conjuntos de entrenamiento y prueba.\n",
    "\n",
    "\n",
    "4. **Modelado**\n",
    "\n",
    "El modelado es la fase en la que se aplican técnicas analíticas avanzadas para resolver las preguntas del negocio. Los analístas suelen probar varios modelos diferentes, ajustando parámetros y volviendo a las fases previas para realizar las transformaciones necesarias. Dependiendo del problema, se suelen utilizar distintos algoritmos como regresiones, árboles de decisión o redes neuronales.\n",
    "\n",
    "\n",
    "5. **Evaluación**\n",
    "\n",
    "Una vez contruidos los modelos, es fundamental evaluarlos para asegurar que cumplen con los requisitos del negocio. En esta fase, los resultados del modelo se comparan con los objetivos comerciales, asegurando que el modelo sea útil y relevante. Esta etapa implica revisar los criterios de rendimiento establecidos al inicio del proyecto y validar los descubrimientos obtenidos.\n",
    "\n",
    "\n",
    "6. **Despliegue**\n",
    "\n",
    "El despliegue es la fase final, enn la que los resultados se implementan dentro del entorno operativo de la organización. Esto puede incluir desde la automatización de decisiones hasta la generación de informes y visualizaciones interactivas. Las tareas típicas incluyen la planificación del despliegue, la creación de documentación y la presentación de los resultados, frecuentemente a través de dashboards o informes finales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c40c8eb",
   "metadata": {},
   "source": [
    "## Aplicaciones de ML\n",
    "\n",
    "### Aplicaciones Iniciales de Mechine Learning\n",
    "\n",
    "El Machine Learning (ML) ha sido adoptados por una amplia gama de industrias debido a su capacidad para automatizar procesos, mojorar la precisión de las predicciones y generar insights que serían difíciles de identificar utilizando métodos tradicionales. A continuación, se presentan algunas de las aplicaciones iniciales más comunes en diferentes sectores, destacando su impacto y beneficios.\n",
    "\n",
    "\n",
    "1. **Sector Financiero**\n",
    "\n",
    "En la industria fianciera el Machine Learning se ha utilizado ampliamente para mojorar la toma de decisiones, gestionar riesgos y detectar fraudes. Las aplicaciones iniciales incluyeron modelos de predicción para evaluar riesgo crediticio y otorgar préstamos. Estos modelos pueden analizar grandes volúmenes de datos históricos para identificar patrones que predigan si un cliente es probable de incumplir un préstamo. Además, el ML ha transformado la detección de fraudes, donde los algorítmos monitorean transacciones en tiempo real para identificar comportamientos sospechosos y prevenir fraudes en taarjetas de crédito.\n",
    "\n",
    "\n",
    "\n",
    "2. **Salud**\n",
    "\n",
    "En el ámbito de la salud las aplicaciones de ML incluyen desde el diagnóstico de enfermedades hasta la personalización de tratamientos. Un ejemplo inicial es el uso de algoritmos para analizar imágenes médicas, como resonancias magnéticas y radiografías, para detectar anomalías que los médicos podrían pasar por alto. Estos sistemas han demostrado ser eficaces en el diagnóstico temprano de enfermedades como en cáncer. Además, el ML se está utilizando para predecir el riesgo de readmisión hospitalaria y ajustar los tratamientos en función de los historiales médicos y datos genéticos de los pacientes.\n",
    "\n",
    "\n",
    "\n",
    "3. **Comercio Electrónico**\n",
    "\n",
    "Los sistemas de recomendación son uno de los ejemplos más conocidos de Machine Learning en el comercio electrónico. Empresas como Amazon y Netflix han utilizado algoritmos de ML para analizar el comportamiento de los usuarios y ofrecer recoemndaciones personalizadas de productos o contenido. Estos sistemas no solo aumentan las ventas al mejorar la experiencia del usuario, sino que también permiten a las empresas optimizar sus estratégias de marketing al dirigir ofertas personalizadas a grupos específicos de clientes.\n",
    "\n",
    "\n",
    "4. **Transporte y Logística**\n",
    "\n",
    "El ML ha revolucionado la industria del transporte y la logística mediante la optimización de rutas y la predicción de demanda. Empresas de transporte como Uber y Lyft utilizan algoritmos de ML para predecir la demanda de viajes y ajustar los precios en tiempo real. Además, en la logistica, el ML se utiliza para optimizar la gestión de inventarios y predecir posibles interrupciones en las cadenas de suministro, lo que permite a las empresas reducir costos y mejorar la eficiencia.\n",
    "\n",
    "\n",
    "5. **Marketing y Publicidad**\n",
    "\n",
    "El ML ha tenido una gran impacto en el marketing digital, donde se utiliza para segmentar audiencias y personalizar campañas publicitarias. Los algoritmos analizan grande volúmenes de datos de comportamiento del consumidor, lo que permite a las empresas dirigirse a clientes potenciales con mensajes personalizados y en el momento adecuado. Además, el ML se utiliza para automatizar la compra de publicidad en tiempo real, optimizando las campañas publicitarias de manera continua para maximizar el retorno de la inversión.\n",
    "\n",
    "\n",
    "6. **Manufactura**\n",
    "\n",
    "En la manufactura, el ML se ha aplicado para mejorar los procesos de producción y mantenimiento predictivo. Las fábricas inteligentes utilizan sensores y algoritmos de ML para monitorear equipos y predecir fallos antes de que ocurran, lo que reduce el tiempo de inactividad y los costos de mantenimiento. Además, se utilizan algoritmos de optimización para ajustar procesos de producción en tiempo real, maximizando la eficiencia y reduciendo el desperdicio.\n",
    "\n",
    "\n",
    "**Impacto de las Aplicaciones de Machine Learning**\n",
    "\n",
    "Las aplicaciones iniciales de Machine Learning han transformado las industrias al automatizar tareas complejas, mejorar la precisión en la toma de decisiones y permitir el análisis de grándes volúmenes de datos en tiempo real. Esto no solo ha permitido una mayor eficiencia operativa, sino que también ha abierto nuevas oportunidades de innovación, mejorando la competitividad de las empresas que lo adoptan.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0319e0",
   "metadata": {},
   "source": [
    "## 10.3 Mejora de modelos\n",
    "\n",
    "### Selección de modelos en ML\n",
    "\n",
    "La selección de modelos es una etapa crítica en los proyectos de Machine Learning, ya que determina qué algoritmo o conjunto de algoritmos se utilizará para resolver un problema específico. Este proceso impica evaluar diferentes modelos en función de varios criterios, con el objetivo de elegir el que ofrezca el mejor rendimiento y se ajuste a las necesidades del proyecto. A continuación se describen los principales aspectos a considerar para seleccionar un modelo adecuado.\n",
    "\n",
    "\n",
    "**1. Precisión**\n",
    "\n",
    "La precisión es uno de los criterios más importantes para la selección de un modelo de ML. Este indicador mide la capacidad de un modelo para hacer predicciones correctas, lo que se evalúa a trevés de métricas como la exactitud (accuracy), la precisión (precision), la exhaustividad (recall) y el puntaje F1. Sin embargo, es crucial no centrarse solamente en la precisión; un modelo puede tener una alta precisión pero un rendimiento deficiente en otras métricas.\n",
    "\n",
    "\n",
    "* **Exactitud (Accuracy):** porcentaje de predicciones correctas sobre el total de predicciones.\n",
    "\n",
    "* **Precisión (Precision):** proporción de verdaderos positivos entre todas las instancias predichas como positivas.\n",
    "\n",
    "* **Exhaustividad:** proporción de verdaderos positivos sobre todas las instancias reales positivas.\n",
    "\n",
    "* **Puntaje F1:** madia armónicaaaa entre precisión y exhaustividad, útil cuando hay un desequilibrio entre clases.\n",
    "\n",
    "\n",
    "\n",
    "**2. Complejidad del Modelo**\n",
    "\n",
    "La complejidad del modelo se refiere a qué tan sofistivado es el algoritmo y cuántos recursos consume durante su entrenamiento y ejecución. Los modelos más complejos, como las redes neuronales profundas, pueden afrecer un rendimiento superior, pero a menudo requieren grnades cantidades de datos, mayor tiempo de procesamiento y son más dificiles de interpretar. En contraposición, los modelos más simples, como las regresiones lineales o los árboles de decisión, son más fáciles de entrenar y entender, aunque pueden ser menos precisos en problemas complejos.\n",
    "\n",
    "El objetivo es encontrar un equilibrio entre la simplicidad y las precisión del modelo, lo que se conoce como *trade-off entre sesgo y varianza*. Un modelo con bajo sesgo y alta varianza podría ajustarse demasiado a los datos de entrenamiento (overfitting), mientras que uno con alto sesgo y baja varianza podría ser demasiado simple y no captar bien las relaciones entre los datos (underfitting).\n",
    "\n",
    "\n",
    "**3. Tiempo de Entrenamiento**\n",
    "\n",
    "El tiempop de entrenamiento es otro factor crucial en la selección de un modelo. Algunos algoritmos, como los k-Nearest Neighbors (k-NN), pueden ser rápidos de implementar pero lentos en la fase de predicción si el conjunto de datos es grande. Por otro lado, algoritmos como los árboles de decisión o las máquinas de soporte vectorial (SVM) pueden tardar más tiempo en entrenarse, pero una vez entrenados, ofrecen predicciones rápidas.\n",
    "\n",
    "Cuando se trabaja con grandes conjuntos de datos o en proyectos donde el tiempo es un recurso limitado, es importante elegir un modelo que ofrezca un equilibrio adecuado entre precisión y velocidad. Además, en aplicaciones de tiempo real, como la predicción de fraudes o los sistemas de recomendación, la velocidad de predicción puede ser más importante que la precisión absoluta.\n",
    "\n",
    "\n",
    "**4. Capacidad de Generalización**\n",
    "\n",
    "Un buen modelo no solo debe ajustarse bien a los datos de entrenamiento, sino también generalizar adecuadamente a nuevos datos no vistos. Esta capacidad de generalización se evalúa a través de la validación cruzada, un método que permite dividir los datos en múltiples subconjuntos (folds) para entrenar y evaluar el modelo en diferentes iteraciones. Esto reduce el riesgo de que el modelo se sobre ajuste (overfitting) a los datos de entrenamiento y no funcione bien con datos nuevos.\n",
    "\n",
    "\n",
    "**5. Interpretabilidad**\n",
    "\n",
    "Dependiendo del proyecto, la interpretación del modelo puede ser un factor clave. En algunas aplicaciones, como el diagnóstico médico o la toma de decisiones financieras, es fundamental que el modelo sea comprensible para los usuarios. Algoritmos simples como las regresiones lineales o los árboles de decisión son fáciles de interpretar y explicar, mientras que los modelos más complejos, como las redes neuronales o los métodos de ensamble (e.g., Random Forest), pueden ser mucho más dificiles de desglosar.\n",
    "\n",
    "En proyectos donde la transparencia y la capacidad de explicar el modelo son cruciales, se tiende a preferir algoritmos más sencillos y comprensibles, incluso si no afrecen la mayor precisión posible.\n",
    "\n",
    "\n",
    "**6. Escalabilidad**\n",
    "\n",
    "La capacidad del modelo para escalar con grandes volúmenes de datos es un criterio importante, especialmente en sectores como el comercio electrónico o las redes sociales, donde los datos pueden crecer rápidamente. Algunos modelos, como las regresiones lineales y los árboles de decisión, son relativamente fáciles de escalar, mientras que otros, como las redes neuronales profundas o los modelos de boosting, pueden enfrentar desafíos significativos en términos de recursos computacionales.\n",
    "\n",
    "\n",
    "\n",
    "**7. Disponibilidad de Datos y Recursos**\n",
    "\n",
    "Finalmente, la cantidad y calidad de los datos disponibles influyen significativamente en las elección del modelo. Algunos modelos, como las redes neuronales profundas, requieren grandes volúmenes de datos para ofrecer un buen rendimiento, mientras que otros, como los árboles de decisión, pueden funcionar bien con menos datos. Además, los recursos disponibles, como el hardware y el tiempo de desarrollo, también juegan un papel importante. Los modelos más complejos pueden requerir hardware especializado, como GPUs para su entrenamiento.\n",
    "\n",
    "\n",
    "**En resumen**, las selección de modelos en Machine Learning depende de varios factores, incluyendo precisión, complejidad, tiempo de entrenamiento, capacidad de generalización, interpretabilidad, escalabilidad y disponibilidad de datos. El objetivo es encontrar un modelo que equilibre estos aspectos de manera adecuada para el problema específico y los recursos disponibles."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
