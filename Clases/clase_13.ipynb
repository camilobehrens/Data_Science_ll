{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f0a965f",
   "metadata": {},
   "source": [
    "# 13. Evaluación de Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43969b82",
   "metadata": {},
   "source": [
    "## 13.1 Matriz de Confisión\n",
    "\n",
    "La **matriz de confusión** es una herramienta que se utiliza para evaluar el desempeño de un modelo de clasificación en problemas de Aprendizaje Supervisado. A diferencia de métricas como el Accuracy, que pueden ser engañosas si el conjunto de datos está desbalanceado, la metriz de confisión proporciona una visión más detallada de los errores cometidos por el modelo.\n",
    "\n",
    "\n",
    "### Estructura de la Matriz de Confusión\n",
    "\n",
    "En una matriz de confusión, los valores reales se organizan en filas y los valores predichos en columnas. La matriz tiene la siguiente estructura básica en un problema de clasificación binaria:\n",
    "\n",
    "|          | **Predicción Positiva** | **Predicción Negativa** |\n",
    "|--------------|--------------|--------------|\n",
    "| **Clase Positiva (1)** | Verdaderos Positivos (TP) | Falsos Negativos (FN) |\n",
    "| **Clase Negativa (0)** | Falsos Positivos (FP) | Verdaderos Negativos (TN) |\n",
    "\n",
    "\n",
    "* **TP (True Positive):** la clase predicha es positiva y corresponde a la clase real positiva.\n",
    "\n",
    "* **TN (True Negative):** la clase predicha es negativa y corresponde a la clase real negativa.\n",
    "\n",
    "* **FP (False Postive):** la clase predicha es positiva pero en realidad es negativa (Error Tipo I).\n",
    "\n",
    "* **FN (False Negative):** la clase predicha es negativa pero en realidad es positiva (Error Tipo II).\n",
    "\n",
    "\n",
    "### Cálculo de la Matriz de Confusión\n",
    "\n",
    "Para calcular una matriz de confusión se requiere un conjunto de datos de prueba. Se predicen las etiquetas de todas las observaciones y se comparan con los valores reales. Cada predicción se clasifica en una de las cuatro categorías mencionadas (TP, TN, FP, FN) y estos valores se colocan en la matriz.\n",
    "\n",
    "\n",
    "### Métricas Derivadas de la Matriz de Confusión.\n",
    "\n",
    "A Partir de la matriz de confusión, se pueden derivar varias métricas para evaluar el desempeño de un modelo de clasificación:\n",
    "\n",
    "* **Accuracy:** mide el porcentaje de predicciones correctas sobre el total de predicciones. \n",
    "\n",
    "        Accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "* **Precision:** indica cuántas de las predicciones positivas realizadas son realmente positivas. \n",
    "\n",
    "        Precision = TP/(TP + FP)  \n",
    "\n",
    "* **Sensibilidad (Recall):** aka tasa de verdaderos positivos, mide la capacidad del modelo para identificar correctamente las instancias positivas.\n",
    "\n",
    "        \n",
    "        Recall = TP/(TP + FN)\n",
    "\n",
    "* **Especificidad:** aka tasa de Verdaderos Negetivos, evalúa la capacidad del modelo para identificar correctamente las instancias negativas. \n",
    "\n",
    "        Specifiicity = TN/(TN + FP)\n",
    "\n",
    "* **F1 Score:** es la media armónica entre la precisión y la sensibilidad. Es útil cuando se busca un balance entre ambas métricas.\n",
    "\n",
    "        F1= 2(Precision x Recall)/(Precision + Recall)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
