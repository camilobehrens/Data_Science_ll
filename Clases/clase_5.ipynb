{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de Datos Limpios\n",
    "\n",
    "## 5.1 Introducción\n",
    "\n",
    "En esta unidad se exploraran los conceptos esenciales de Data Wrangling y Limpieza de Datos, dos procesos fundamentales en la ciencia de datos y Machine Learning. La capacidad de transformar y limpiar los datos es crucial para asegurar la calidad y precisión de los análisis y modelos predictivos que desarrollamos.\n",
    "\n",
    "El **Data Wrangling** se refiere al proceso de transformación y organización de datos crudos en un formato más adecuado para su análisis. Este proceso puede incluir tareas como la eliminación de duplicados, el tratamiento de valores nulos, la combinación de diferentes fuentes de datos y la modificación de estructuras de datos para mejorar su accesibilidad y usabilidad. \n",
    "\n",
    "La **Limpieza de Datos** por su parte se enfoca en identificar y corregir errores, inconsistencias y datos incompletos, garantizando que los conjuntos de datos sean lo más precisos y completos posible antes de su uso en análisis o modelos de Machine Learning.\n",
    "\n",
    "Esta unidad se centrará en:\n",
    "\n",
    "* **Buenas prácticas de Data Wrangling** : estrategias para manejar datos de manera efectiva y evitar errores comunes.\n",
    "\n",
    "* **Herramientas y Librerías**: se explorarán las principales herramientas y librerías que facilitan estos procesos, como Pandas en Python.\n",
    "\n",
    "* **Técnicas de transformación de datos**: se aprenderá a aplicar técnicas de transformación que mejoran la calidad y estructura de los datos.\n",
    "\n",
    "El objetivo es que se adquieran habilidades prácticas para manejar y preparar datos, un paso crítico que impacta directamente e el éxito de cualquier proyecto de ciencia de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Transformación de Datos\n",
    "\n",
    "### Transformación de Datos: procesos, beneficios y desafíos\n",
    "\n",
    "La **transformación de datos** es un proceso clave en la ciencia de datos que implica cambiar el formato, la estructura o los valores de los datos para hacerlos más útiles y accesibles para análisis y modelos predictivos. Este proceso es esencial para preparar los datos , asegurando su calidad y consistencia, lo cual impacta directamente en la precisión de los resultados de Machine Learning.\n",
    "\n",
    "\n",
    "### Procesos de Transformación de Datos\n",
    "\n",
    "Los procesos de transformación de datos pueden clasificarse en varias categorías:\n",
    "\n",
    "1. **Procesos Constructivos:**\n",
    "    * involucran la agregación, copia y replicación de datos.\n",
    "    * ejemplos: fusionar varios conjuntos de datos para crear uno más rico y detallado.\n",
    "\n",
    "2. **Procesos Destructivos:**\n",
    "    * incluyen la eliminación de campos y registros que no son necesarios para el análisis.\n",
    "    * por ejemplo, remover columnas redundantes o filas con datos irrelevantes para el estudio.\n",
    "\n",
    "3. **Procesos Estéticos:** \n",
    "    * se centran en la estandarización de valores y nombres para mantener la uniformidad.\n",
    "    * por ejemplo, renombrar columnas para hacerlas más descriptivas o convertir datos numéricos a formatos más amigables.\n",
    "\n",
    "4. **Procesos Estructurales:**\n",
    "    * enfocados en renombrar, mover y combinar columnas dentro de una base de datos.\n",
    "    * ejemplo: reorganizar columnas para mejorar la legibilidad y la lógica de los datos.\n",
    "\n",
    "\n",
    "### Beneficios de la Transformación de Datos\n",
    "\n",
    "* **Mejora de la calidad de los datos:** los datos transformados están mejor organizados, son más fáciles de analizar y ayudan a evitar problemas como valores duplicados, nulos o formatos incompatibles.\n",
    "\n",
    "* **Compatibilidad entre sistemas:** facilita que los datos se puedan utilizar entre diferentes aplicaciones y sistemas, permitiendo múltiples contextos y propósitos.\n",
    "\n",
    "* **Facilita el análisis:** los datos correctamente transformados son más comprensibles y permiten un análisis más preciso y eficiente, optimizando los tiempos de procesamiento.\n",
    "\n",
    "\n",
    "### Desafíos de la Transformación de Datos\n",
    "\n",
    "* **Costo y recursos:** el proceso puede ser costoso en términos de infraestructura y herramientas, además de ser demandante en recursos computacionales.\n",
    "\n",
    "* **Errores por falta de experiencia:** la falta de conocimientos especificos puede llevar a errores durante la transformación,como problemas con la imputación de valores o la detección de duplicados.\n",
    "\n",
    "* **Inadecuación a las necesidades:** la transformaciones realizadas pueden no ajustarse correctamente a los requisitos del proyecto, lo que puede afectar la calidad del análisis posterior.\n",
    "\n",
    "\n",
    "La transformación de datos es por tanto un proceso fundamental en cualquier proyecto de ciencia de datos, permitiendo no solo preparar los datos para el análisis, sino también mejorar su calidad y aplicabilidad en diferentes contextos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Buenas Prácticas en Data Wrangling\n",
    "\n",
    "### Recomendaciones para el manejo de datos\n",
    "\n",
    "El manejo adecuado de los datos es un componente esencial en la ciencia de datos, ya que garantiza que los datos sean útiles, precisos y relevantes para los análisis y modelos. A continuación se describen algunas recomendaciones clave para optimizar el manejo de datos durante el proceso de Data Wrangling: \n",
    "\n",
    "### 1. Filtra tus Datos para aligerar la carga\n",
    "\n",
    "* filtar datos consiste en seleccionar solo la información relevante para tu análisis, eliminando datos innecesarios que puedan relentizar los procesos de manipulación y análisis.\n",
    "* Ejemplo, si se está analizando la evolución de ventas en un periodo específicos de tiempo, se pueden filtrar los datos para excluir años o regiones que no son de interés, lo que facilita un análsis más ágil y precioso.\n",
    "\n",
    "\n",
    "### 2. Considerar el resultado deseado durante la manipulación de datos\n",
    "\n",
    "* es crucial tener en mente el objetivo final de la manipulación de datos desde el inicio. Esto ayuda a tomar decisiones adecuadas sobre cómo transformar y limpiar los datos para alinearse con los resultados esperados del análisis.\n",
    "\n",
    "* Ejemplo, si el objetivo es predecir ventas futuras, el enfoque durante la manipulación de datos debe estar en mantener variables que influyan directamente en el modelo predictivo y transformar los datos en un formato compatuble con las técnicas de medelado seleccionadas.\n",
    "\n",
    "\n",
    "### 3. Mantener siempre la capacidad de retroceder a una versión anterior de los datos\n",
    "\n",
    "* implementar versiones de control durante el proceso de manipulación de datos e fundamental para poder deshacer cambios si se detectan errores o inconsistencias en las transformaciones aplicadas.\n",
    "\n",
    "* Ejemplo, utilizar sistemas de control de versiones o guardar copias de los datos en etapas clave del proceso permite regresar a estados anteriores, facilitando correcciones sin perder todo el progreso realizado.\n",
    "\n",
    "\n",
    "### 4. Entiendo Dónde y Cómo están guardados los datos\n",
    "\n",
    "* conocer la ubicación y el formato de almacenamiento de los datos es crucial para planificar adecuadamente los procesos de manipulación. Esto incluye la familiarización con bases de datos, archivos planos o servicios en la nube.\n",
    "\n",
    "* Ejemplo, en un entorno corporativo es común que losdatos estén distribuidos en diferentes bases de datos.Entender cómo están estructurados y almacenados facilita el acceso y la integración durante el Data Wrangling.\n",
    "\n",
    "\n",
    "### 5. Crear un Diccionario de Datos\n",
    "\n",
    "* un diccionario de datos documenta todas las variables, su significado y sus formatos, proporcionando un recurso de referencia que ayuda a entender los datos de manera más profunda.\n",
    "\n",
    "* Ejemplo, el diccionario de datos es útil para equipos de trabajo,ya que asegura que todos los miembros comprendan cómo se deben interpretar las variables, especialmente en proyectos colaborativos.\n",
    "\n",
    "\n",
    "### 6. Incluir un experto en la materia siempre que sea posible\n",
    "\n",
    "* involucrar a expertos que comprendad el contexto del dominio de los datos mejora la calidad del proceso de Data Wrangling, ya que aportan conocimientos específicos sobre el significado y la importancia de ciertas variables.\n",
    "\n",
    "* Ejemplo, un experto en finanzas puede guiar el manejo de datos contables, asegurando que las transformaciones y manipulaciones respeten la lógica financiera necesaria para un análisis precioso.\n",
    "\n",
    "\n",
    "Estas transformaciones no solo mejoran la calidad de los datos, sino que también optimizan la eficiencia del proceso de manipulación, ayudando a evitar errores comunes y garantizando que los datos estén alineados con los objetivos del análisis o medelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Revisión de Pares y Feedback\n",
    "\n",
    "### Proceso de Revisión de pares en data wrangling\n",
    "\n",
    "La revisión de pares es un proceso fundamental en la ciencia de datos que permite validar los métodos y resultados de la manipulación de datos a través del feedback de colegas o expertos. Este proceso no solo mejora la calidad de los análisis sino que también fomenta la colaboración y el aprendizaje mutuo entre los miembros del equipo.\n",
    "\n",
    "La revisión de pares se enfoca en evaluar la coherencia, la precisión y la efecividad de los procesos utilizados en la manipulación y limpieza de datos, asegurando que estos sean adecuados para cumplir con los objetivos del proyecto. A continuación se detallan los puntos de control esenciales durante una revisión de pares:\n",
    "\n",
    "**Puntos de Control en la Revisión de Pares**\n",
    "\n",
    "1. **Motivación:**\n",
    "    * Este punto de control evalúa el propósito y la razón detrás de las decisiones tomadas durante el proceso de manipulación de datos. Es esencial que los pasos dados tengan una justificación clara y estén alineados con las necesidades del proyecto.\n",
    "    \n",
    "    * Ejemplo, verificar si la eliminación de ciertos valores nulos o la transformación de datos fue motivada por la necesidad de mejorar la presición del modelo o facilitar la interpretación de los resultados.\n",
    "\n",
    "2. **Objetivos:**\n",
    "    * Los objetivos de la manipulación de datos deben estar claramente definidos y ser medibles. Este punto de control asegura que cada transformación y limpieza realizada contribuya directamente a alcanzar los resultados esperados del análisis.\n",
    "\n",
    "    * Por ejemplo, comprobar si las tareas de limpieza y transformación están orientadas a preparar los datos para un modelo de ML específico, asegurando que todas las variables necesarias estén correctamente procesadas y disponibles.\n",
    "\n",
    "\n",
    "3. **Estructura:**\n",
    "    * La estructura se refiere a la forma en la que se han organizado y documentado los procesos de Data Wrangling. Un proceso bien estructurado permite una comprensión fácil y replicable de las etapas realizadas.\n",
    "\n",
    "    * Por ejemplo, revisar si se ha mantenido una secuencia lógica en la transformación de datos, como la eliminación de duplicados antes de agrupar los datos, o si se ha seguido una nomenclatura consistente en el nombre de las variables para evitar confusiones.\n",
    "\n",
    "\n",
    "### Importancia de la Revisión de Pares\n",
    "\n",
    "* **Mejora de la calidad:** permite detectar errores o inconsistencias que podrían pasar desapercibidos en la manipulación individual, asegurando que los datos finales sean fiables.\n",
    "\n",
    "* **Aseguramiento del Cumplimiento de Estándares:** facilita que el proceso de Data Wrangling cumpla con los estándares y mejores prácticas del equipo o la organización.\n",
    "\n",
    "* **Aprendizaje y colaboración:** la revisión de pares fomenta un ambiente de aprendizaje continuo, donde los miembros del equipo pueden compartir conocimientos y mejorar sus habilidades en la manipulación de datos.\n",
    "\n",
    "\n",
    "La revisión de pares es un  proceso crítico que no solo valida la calidad de los procesos, sino que también contribuye al desarrollo profesional de los involucrados, asegurando que los datos manipulados sean aptos para el análisis y alineados con los objetivos del proyecto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Actividad práctica\n",
    "\n",
    "**Consigna**\n",
    "\n",
    "* iniciar el proceso de limpieza de datos.\n",
    "* explorar los tipos de las columnas y modificar según corresponda.\n",
    "* Validar la presencia de valores perdidos y sugerir alguna solución.\n",
    "* Validar la presencia de valores outliers y segerir alguna solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Cows  Goats\n",
      "Year 1    12     22\n",
      "Year 2    20     19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Cows': [12, 20], 'Goats': [22, 19]}, index=['Year 1', 'Year 2'])\n",
    "df.to_csv('animals.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. EDA y visualización de Datos.\n",
    "\n",
    "Lo escribo aquí para evitar problemas al sincronizar con pc, ya que olvidé cargar lo que hice ayer en la pc. ayer hice en la pc el 6.1\n",
    "\n",
    "\n",
    "## 6.2 Análisis Exploratorio de Datos (EDA)\n",
    "\n",
    "# Definición del EDA y su propósito\n",
    "\n",
    "El Análisis Exploratorio de Datos (EDA, por sus siglas en inglés) es una técnica utilizada para explorar, resumir y visualizar datos antes de aplicar modelos estadísticos o de machine learning. su propósito principal es proporcionar un entendimiento profundo y detallado de los datos, permitiendo identificar patrones, detectar anomalías y formular hipótesis iniciales.\n",
    "\n",
    "El EDA actúa comoun puente entre la recolección de datos y la aplicación de modelos analíticos, ayudando a los científicos de datos a tomar decisiones informadas sobre cómo proceder en el análisis posterior. A través de gráficos y análisis estadísticos básicos, el EDA permite observar las caracterísitocas de los datos y sus relaciones internas. \n",
    "\n",
    "\n",
    "# Utilidades del EDA\n",
    "\n",
    "el EDA es una herramienta poderosa que facilita la comprensión de los datos mediante diversas utilidades, tales como:\n",
    "\n",
    "* **Detección de Outliers:** los valores atípicos son datos que se alejan significativamente del resto de abservaciones y pueden distorsionar los resultados del análisis. El EDA permite identificar y evaluar estos outliers, ayudando a decidir si deben ser tratados o mantenidos en el conjunto de datos.\n",
    "\n",
    "* **Identificación de Patrones de Datos Ausentes:** los datos faltantes pueden afectar la calidad del análisis si no se gestionan correctamente.El EDA ayuda a detectar la presencia de valores ausentes, identificar patrones sistemáticos y decidir el major enfoque para tratarlos, ya sea mediante la imputación de valores o la eliminación de registros incompletos.\n",
    "\n",
    "* **Detección de Sesgos y Errores en la Codificación de Datos:** a través del EDA se pueden adentificar posibles sesgos en los datos y errores en su codificación, permitiendo corregirlos antes de avanzar a etapas más complejas.\n",
    "\n",
    "* **Evaluación de la Distribución de las Variables:** examinar cómo se distribuyen los datos permite identificar asimetrías, curtosis y otras características que podrían influir en los resultados de modelos analíticos.\n",
    "\n",
    "\n",
    "# Etapas del EDA\n",
    "\n",
    "El proceso de EDA se dasarrolla en varias etapas, cada una con un objetivo específico que contribuye al entendimiento global del conjunto de datos:\n",
    "\n",
    "1. **Preparación de Datos:**\n",
    "    * En esta etapa los datos se organizan y se hacen accesibles para el análisis. Incluye la limpieza de datos, transformación de variables, combinación de conjuntos de datos y la selección de subconjunto relevantes. Esta preparación asegura que los datos estén en un formato adecuado para los análisis posteriores.\n",
    "\n",
    "\n",
    "2. **Examen Gráfico de los Datos:**\n",
    "    * Se realiza un análisis visual de las variables mediante gráficos como histogramas, gráficos de dispersión y graficos de caja. Esto facilita la identificación de patrones, tendencias, posibles errores de codificación y proporciona una visión inicial sobre la naturaleza de los datos.\n",
    "\n",
    "3. **Análisis de Correlaciones y Dependencias:** \n",
    "    * Esta etapa se centra en evaluar la relación entre variables utilizando medidas como la correlación de Pearson para variables numéricas o la correlación de Spearman para datos ordinales. Es importante recordar que correlación no implica causalidad, por lo que los resultados deben interpretarse con cuidado.\n",
    "\n",
    "4. **Evaluación de Supuestos Distribucionales:** \n",
    "    * Se aanalizan las distribuciones de las variables para determinar si cumplen con los supuestos necesarios para la aplicación de modelos estadísticos. Esta etapa incluye el análisis de la asimetría y la curtosis de las variables, ayudando a decidir si es necesario aplicar transformaciones adicionales. \n",
    "\n",
    "\n",
    "\n",
    "# Conceptos Clave\n",
    "\n",
    "* **Valores perdidos:** datos ausentes pueden introducir sesgos en el análisis. Su identificación y tratamiento son cruciales para mantener la integridad del conjunto de datos. \n",
    "\n",
    "* **Correlaciones y Dependencias:** miden la relación lineal entre dos o más variables. Es esencial diferenciar entre correlación causalidad para evitar conclusiones erróneas.\n",
    "\n",
    "* **Análisis Estadístico:** incluye la evaluación de métricas descriptivas como la media, mediana, desviasión estándar y la identificación de patrones dentro de los datos. Esta etapa proporciona un marco para entender mejor la naturaleza de los datos u su variabilidad.\n",
    "\n",
    "\n",
    "El EDA es una etapa crítica crítica en el proceso de análisis de datos. Proporcionan un primer vistazo a los datos, permitiendo descubrir información clave que guiará las siguientes fases del análisis. al comprender sus utilidades y etapas, los cientificos de datos pueden optimizar la preparación y exploración de datos, asegurando un análisis riguroso y detallado. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de EDA en Python\n",
    "\n",
    "# 1. Impotar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "# 2. Cargar datos\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indices",
   "language": "python",
   "name": "indices"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
